url <- xml_attr(xml_find_all(page, "//article[@class='product_pod'/div[@class='image_container']/a"), "href")
length(url)
url
url <- xml_attr(xml_find_all(page, "//article[@class='product_pod']/div[@class='image_container']/a"), "href")
length(url)
url
title <- xml_text(xml_find_all(page, "//article[@class='product_pod']/h3/a"), "title")
title
star <- xml_attr(xml_find_all(page, "//article[@class='product_pod']/p"), "class")
star
price <- xml_text(xml_find_all(page, "//article[@class='product_pod']/div[@class='product_price']/p"), "title")
price
availability <- xml_text(xml_find_all(page, "//article[@class='product_pod']//p[@class='instock availability']"))
availability
View(books)
rm(list=ls())
library(xml2)
page <- read_html("http://books.toscrape.com/")
page
class(page)
product <- xml_find_all(page, "//article[@class='product_pod']")
product
length(product)
url <- xml_attr(xml_find_all(page, "//article[@class='product_pod']/div[@class='image_container']/a"), "href")
length(url)
url
title <- xml_text(xml_find_all(page, "//article[@class='product_pod']/h3/a"), "title")
title
star <- xml_attr(xml_find_all(page, "//article[@class='product_pod']/p"), "class")
star
price <- xml_text(xml_find_all(page, "//article[@class='product_pod']/div[@class='product_price']/p"), "title")
price
availability <- xml_text(xml_find_all(page, "//article[@class='product_pod']//p[@class='instock availability']"))
availability
books <- data.frame(url, title, star, price, availability)
View(books)
rm(list=ls())
library(xml2)
page <- read_html("http://books.toscrape.com/")
page
class(page)
product <- xml_find_all(page, "//article[@class='product_pod']")
product
length(product)
url <- xml_attr(xml_find_all(page, "//article[@class='product_pod']/div[@class='image_container']/a"), "href")
length(url)
url
title <- xml_text(xml_find_all(page, "//article[@class='product_pod']/h3/a"), "title")
title
star <- xml_attr(xml_find_all(page, "//article[@class='product_pod']/p"), "class")
star
price <- xml_text(xml_find_all(page, "//article[@class='product_pod']/div[@class='product_price']/p[1]"), "title")
price
availability <- xml_text(xml_find_all(page, "//article[@class='product_pod']//p[@class='instock availability']"))
availability
books <- data.frame(url, title, star, price, availability)
View(books)
#################
#Exercise 1
books$url <- paste("http://books.toscrape.com/", books$url, sep="")
books$star[books$star== "star-rating One"] <- 1
books$star[books$star== "star-rating Two"] <- 2
books$star[books$star== "star-rating Three"] <- 3
books$star[books$star== "star-rating Four"] <- 4
books$star[books$star== "star-rating Five"] <- 5
books$star <- as.integer(books$star)
books$star
#strip non numeric char
books$price <- gsub("Â£", "", books$price)
books$price <- as.numeric(books$price)
books$price
books$availability <- trimws()
url2 <- character(0)
title2 <- character(0)
star2 <- character(0)
price2 <- character(0)
availability2 <- character(0)
for(i in 1:50) {
link <- paste("http://books.toscrape.com/catalogue/page-", i, ".html")
url <- xml_attr(xml_find_all(page, "//article[@class='product_pod']/div[@class='image_container']/a"), "href")
length(url)
url
url2 <- c(url2, url)
title <- xml_text(xml_find_all(page, "//article[@class='product_pod']/h3/a"), "title")
title
title2 <- c(title2, title)
star <- xml_attr(xml_find_all(page, "//article[@class='product_pod']/p"), "class")
star
star2 <- c(star2, star)
price <- xml_text(xml_find_all(page, "//article[@class='product_pod']/div[@class='product_price']/p[1]"), "title")
price
price2 <- c(price2, price)
availability <- xml_text(xml_find_all(page, "//article[@class='product_pod']//p[@class='instock availability']"))
availability
availability2 <- c(availability2, availability)
}
#Exercise 4
page
copies <- xml_text(xml_find_all(page, "//table//th[text()='Availabilitiy']/following-sibling::td"))
copies <- xml_text(xml_find_all(page, "//table/tr[6]/td"))
copies <- gsub(" available)", "",copies)
copies <- gsub("	In stock (", "",copies)
#Exercise 4
page
copies <- xml_text(xml_find_all(page, "//table//th[text()='Availabilitiy']/following-sibling::td"))
copies <- xml_text(xml_find_all(page, "//table/tr[6]/td"))
copies <- gsub(" available", "",copies)
copies <- gsub("	In stock ", "",copies)
copies
page
copies <- xml_text(xml_find_all(page, "//table//th[text()='Availabilitiy']/following-sibling::td"))
copies <- xml_text(xml_find_all(page, "//table/tr[6]/td"))
copies <- gsub(" available)", "",copies)
copies <- gsub("	In stock (", "",copies)
copies <- xml_text(xml_find_all(page, "//table//th[text()='Availabilitiy']/following-sibling::td"))
copies
copies <- xml_text(xml_find_all(page, "//table/tr[6]/td"))
source("~/Desktop/juanxue_LabExercise8.R", echo=TRUE)
page
copies <- xml_text(xml_find_all(page, "//table//th[text()='Availabilitiy']/following-sibling::td"))
copies <- xml_text(xml_find_all(page, "//table/tr[6]/td"))
copies <- gsub(" available)", "",copies)
copies <- gsub("	In stock (", "",copies)
copies <- xml_text(xml_find_all(page, "//table/tr[6]/td"))
copies <- gsub(" available)", "",copies)
copies <- gsub("	In stock (", "",copies)
copies <- gsub("In stock (", "",copies)
copies <- gsub("[^0-9]", "",copies)
copies
copies <- as.integer()(copies)
copies <- gsub("In stock (", "",copies, fixed = TRUE)
copies <- gsub("[^0-9]", "",copies)
copies
library(rattle)
rattle()
library(rattle)
rattle()
library(rattle)
rattle()
library(rattle)
rattle()
rattle()
rm(list=())
rm(list=""
rm(list=""
rm(list="")
rm(ls=(""))
rm(list=ls())
library(swirl)
swirl()
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
?sapply
sapply(cls_list)
cls_vect <- (cls_list)
cls_vect <- (cls_list, as.vector())
cls_vect <- (cls_list, vector
cls_vect <- (cls_list, vector)
cls_vect <- sapply(cls_list)
cls_vect <- sapply(cls_list, flags)
cls_vect <- sapply(cls_list, name <- function(variables) {
})
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[, 11:17]
head()
head(flag_colors)
lapply(flag_colors, class)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[, 19:23]
lapply(flag_shapes, range)
sapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply(flags, unique)
unique_vals
unique_vals <- lapply(flags, length)
sapply(unique_vals, length)
lapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
reflection <- "This tutorial taught me how to use sapply and lapply"
save.image("juanxue_tutorial10.rda")
rm(list=ls())
swirl()
sapply(flags. unique)
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
summary(flags$population)
tapply(flags, population, summary)
tapply(flags$population, flags$landmass, summary)
reflection("In this tutorial, I learnt vapply and tapply")
reflection <- "In this tutorial, I learnt vapply and tapply"
save.image("juanxue_tutorial11.rda")
rm(list=())
rm(list=())
rm(list=ls())
La
install.packages("httr")
library(httr)
library(jsonlite)
url<-"http://iot-bais.azurewebsites.net/temperatures"
temperature <- GET(url)
library(rattle)
rattle()
rattle()
rattle()
install.packages(POSIXlt)
install.packages('POSIXlt')
?as.POSIXlt
?as.POSIXct
install.packages(Rsocrate)
install.packages('Rsocrate')
install.packages('Quandl')
install.packages('Rsocrata')
install.packages('RSocrata')
#################################
#Exercice 3
url <- "https://data.iowa.gov/resource/mw8r-vqy4.json?where=age_at_release='25-34' OR age_at_release='Under 25'"
recidivism_young <- read.socrata(url)
library(RSocrata)
#################################
#Exercice 3
url <- "https://data.iowa.gov/resource/mw8r-vqy4.json?where=age_at_release='25-34' OR age_at_release='Under 25'"
recidivism_young <- read.socrata(url)
#################################
#Exercice 3
recidivism_young<-read.socrata("https://data.iowa.gov/resource/mw8r-vqy4.json?$where=age_at_release='25-34' OR age_at_release='Under 25'")
library(rattle)
rattle()
library(rattle)
rattle()
rm(list=ls())
library(swirl)
swirl()
data(cars)
cars
help(cars)
head(cars)
plot(cars)
?plot
plot(x = cars$speed, y = cars$dist)
plot(dist ~ speed, cars)
plot(x = cars$dist, y = cars$speed)
plot(x = cars$speed, y = cars$dist)
plot(x = cars$speed, y = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab= "Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab= "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab= "Stopping Distance", title="My Plot")
plot(cars, main = "My Plot")
plot(cars, sub="My Plot Subtitle")
plot(cars, col =2)
plot(cars, xlim = c(10,15))
plot(cars, pch = 2)
plot(mtcars)
data(mtcars)
boxplot()
?boxplot
boxplot(formula(mpg,cyl),data(mtcars))
boxplot(formula=(mpg,cyl),data(mtcars))
boxplot(formula=(mpg,cyl),data(mtcars))
boxplot(formula=(mpg,cyl),data(mtcars)))
boxplot(
)
boxplot(data(mtcars))
boxplot(formula(mpg ~ cyl),data(mtcars))
boxplot(formula(mpg ~ cyl),data(mtcars))
help
boxplot(formula = mpg ~ cyl, data = mtcars)
hist()
hist(mtcars$mpg)
reflection <- "in this tutorial, I learnt how to create different kind of charts"
save.image("juanxue_tutorial15.rda")
library(rattle)
rattle()
library(rattle)
rattle()
View(gvd2)
install.packages("reshape2")
---
title: "HW5"
---
title: "HW5"
knitr::opts_chunk$set(echo = TRUE)
clear the enviroment
clear the enviroment
rm(list=ls())
You will need GGPlot and XML2.
## clear the enviroment
```{r}
## clear the enviroment
```{r}
library("ggplot2")
library("xml2")
library("ggplot2")
library("xml2")
You will need GGPlot and XML2.
You will need GGPlot and XML2.
**install.packages("ggplot2")**
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
ggplot(nhl[which(nhl$year == 1990 & nhl$wins > 40), c("team", "wins")], aes(x = reorder(team, wins), y = wins, fill = team)) +
geom_bar(stat = "identity", width=.75) +
coord_flip() +
theme(legend.position="none") +
ggtitle("NHL Teams > 40 Wins in 1990") +
xlab("NHL Team") + ylab("Wins")
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
library(ggplot2)
ggplot(nhl[which(nhl$year == 1990 & nhl$wins > 40), c("team", "wins")], aes(x = reorder(team, wins), y = wins, fill = team)) +
geom_bar(stat = "identity", width=.75) +
coord_flip() +
theme(legend.position="none") +
ggtitle("NHL Teams > 40 Wins in 1990") +
xlab("NHL Team") + ylab("Wins")
for (i in 1:3){  #24 pages of data
Sys.sleep(5) # Add 5-second wait time
# Paste number (1, 2, 3, ...) at end of base URL
url<-paste("https://www.scrapethissite.com/pages/forms/?page_num=", i, sep="")
page<-read_html(url)
name<-xml_text(xml_find_all(page, "//td[@class='name']"))
names<-c(names, name) # Append to names vector
year<-xml_text(xml_find_all(page,"//td[@class='year']"))
years<-c(years, year) # Append to years vector
win<-xml_text(xml_find_all(page,"//td[@class='wins']"))
wins<-c(wins, win) # Append to wins vector
loss<-xml_text(xml_find_all(page, "//td[@class='losses']"))
losses<-c(losses, loss) # Append to losses vector
}
rm(list=ls())
library(ggplot2)
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
## Prerequisites
You will need GGPlot and XML2.
## Details
In this assignment I will demonstrate how to scrape, clean and combine data sets. In addition, I will demonstrate how to generate summary statisics and simple plots. I will be scraping initial NHL data from [Scrape This Site](https://www.scrapethissite.com/pages/forms/).
Clear your environment.
rm(list=ls())
library(xml2)
names<-character(0)
years<-character(0)
wins<-character(0)
losses<-character(0)
for (i in 1:3){  #24 pages of data
Sys.sleep(5) # Add 5-second wait time
# Paste number (1, 2, 3, ...) at end of base URL
url<-paste("https://www.scrapethissite.com/pages/forms/?page_num=", i, sep="")
page<-read_html(url)
name<-xml_text(xml_find_all(page, "//td[@class='name']"))
names<-c(names, name) # Append to names vector
year<-xml_text(xml_find_all(page,"//td[@class='year']"))
years<-c(years, year) # Append to years vector
win<-xml_text(xml_find_all(page,"//td[@class='wins']"))
wins<-c(wins, win) # Append to wins vector
loss<-xml_text(xml_find_all(page, "//td[@class='losses']"))
losses<-c(losses, loss) # Append to losses vector
}
names = trimws(gsub("\n", "", names))
years = trimws(gsub("\n", "", years))
wins = trimws(gsub("\n", "", wins))
losses = trimws(gsub("\n", "", losses))
nhl$year <- as.integer(nhl$year)
nhl<-data.frame(team=names, year=years, wins=wins, losses=losses)
nhl$year <- as.integer(nhl$year)
nhl$wins <- as.integer(nhl$wins)
nhl$losses <- as.integer(nhl$losses)
str(nhl)
nhl[1:10, ]
library(ggplot2)
ggplot(nhl[which(nhl$year == 1990 & nhl$wins > 40), c("team", "wins")], aes(x = reorder(team, wins), y = wins, fill = team)) +
geom_bar(stat = "identity", width=.75) +
coord_flip() +
theme(legend.position="none") +
ggtitle("NHL Teams > 40 Wins in 1990") +
xlab("NHL Team") + ylab("Wins")
install.packages(NLP)
install.packages(tm)
install.packages('tm')
install.packages('NLP')
install.packages('Snowballlc')
install.packages('RColorBrewer')
install.packages('wordcloud')
install.packages(SnowballC)
install.packages('SnowballC')
library('rattle')
rattle()
#Data Wrangling Final Project
#Angel C, Juanxi X.
#### 1. Stream in and filter
#### 2. Original Data Processing and Merging
#### 3. Data Imputation and Variable Creation
#### 4. Data Visualization and analysis
rm(list = ls())
library(dplyr)
########################################
#### 1. Stream in and filter
weather <- read.csv("Chicago_weather.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE, na.strings = "")
setwd("~/Documents/GitHub/CTA_Ridership_Analysis")
#Data Wrangling Final Project
#Angel C, Juanxi X.
#### 1. Stream in and filter
#### 2. Original Data Processing and Merging
#### 3. Data Imputation and Variable Creation
#### 4. Data Visualization and analysis
rm(list = ls())
library(dplyr)
########################################
#### 1. Stream in and filter
weather <- read.csv("Chicago_weather.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE, na.strings = "")
cta <- read.csv("CTA_ridership.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
holiday_2022 <- read.csv("holiday2022.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
holiday <- read.csv("US_holiday.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)
#format dates
cta$service_date <- as.POSIXct(cta$service_date, format = "%m/%d/%Y")
holiday$Date <- as.POSIXct(holiday$Date, format = "%Y-%m-%d")
holiday_2022$date <- as.POSIXct(holiday_2022$date, format = "%m/%d/%Y")
weather$date <- weather$Measurement.Timestamp
weather$date <- substr(weather$date, 1, 10)
weather$date <- as.POSIXct(weather$date, format = "%m/%d/%Y")
#filter dates
holiday <- holiday[holiday$Date >= "2015-05-26" & holiday$Date <= "2022-07-31",]
cta <- cta[cta$service_date >= "2015-05-26" & cta$service_date <= "2022-07-31",]
########################################
#### 2. Original Data Processing and Merging
#change column names
names(weather)[names(weather) == "Air.Temperature"] <- "temperature"
names(weather)[names(weather) == "Rain.Intensity"] <- "rain"
names(weather)[names(weather) == "Wind.Speed"] <- "wind_speed"
names(cta)[names(cta) == "service_date"] <- "date"
names(holiday)[names(holiday) == "Holiday"] <- "holiday"
names(holiday)[names(holiday) == "Date"] <- "date"
#select columns
weather <- weather[,c("date", "temperature", "rain", "wind_speed")]
holiday <- holiday[,c("date", "holiday")]
#clean out weather data
weather <- na.omit(weather)
weather <- group_by(weather, date) %>% summarise(temperature = mean(temperature), rain = sum(rain), wind_speed = mean(wind_speed))
#merge
holiday <- rbind(holiday, holiday_2022)
cta_holiday <- merge(cta, holiday, by = "date", all.x = TRUE)
cta_holiday_weather <- merge(cta_holiday, weather, by = "date", all.x = TRUE)
########################################
#### 3. Data Imputation and Variable Creation
#Impute empty values in weathers data
cta_holiday_weather$temperature[is.na(cta_holiday_weather$temperature)] <-
(cta_holiday_weather$temperature[is.na(cta_holiday_weather$temperature) - 5] +
cta_holiday_weather$temperature[is.na(cta_holiday_weather$temperature) + 5]) / 2
cta_holiday_weather$rain[is.na(cta_holiday_weather$rain)] <-
(cta_holiday_weather$rain[is.na(cta_holiday_weather$rain) - 5] +
cta_holiday_weather$rain[is.na(cta_holiday_weather$rain) + 5]) / 2
cta_holiday_weather$wind_speed[is.na(cta_holiday_weather$wind_speed)] <-
(cta_holiday_weather$wind_speed[is.na(cta_holiday_weather$wind_speed) - 5] +
cta_holiday_weather$wind_speed[is.na(cta_holiday_weather$wind_speed) + 5]) / 2
#create new variables rain_type and wind_type
#Rain Weather Type: less than 10 rain is clear, between 10 and 40 is drizzle, between 40 and 80 is rain, more than 80 is heavy rain
cta_holiday_weather$rain_type <- ifelse(cta_holiday_weather$rain > 80, "heavy rain",
ifelse(cta_holiday_weather$rain >= 40 & cta_holiday_weather$rain < 80, "rain",
ifelse(cta_holiday_weather$rain >= 10 & cta_holiday_weather$rain < 40, "drizzle", "clear")))
#Wind Weather Type: less than 10 is calm, between 10 and 20 is light breeze, between 20 and 30 is breeze, between 30 and 40 is strong breeze, between 40 and 50 is gale, more than 50 is storm
cta_holiday_weather$wind_type <- ifelse(cta_holiday_weather$wind_speed < 10, "calm",
ifelse(cta_holiday_weather$wind_speed >= 10 & cta_holiday_weather$wind_speed < 20, "light breeze",
ifelse(cta_holiday_weather$wind_speed >= 20 & cta_holiday_weather$wind_speed < 30, "breeze",
ifelse(cta_holiday_weather$wind_speed >= 30 & cta_holiday_weather$wind_speed < 40, "strong breeze",
ifelse(cta_holiday_weather$wind_speed >= 40 & cta_holiday_weather$wind_speed < 50, "gale", "storm")))))
#create a month column
cta_holiday_weather$month <- substr(cta_holiday_weather$date, 6, 7)
#create a year column
cta_holiday_weather$year <- substr(cta_holiday_weather$date, 1, 4)
########################################
#### 4. Data Visualization and analysis
library(ggplot2)
cta_holiday_weather$year <- substr(cta_holiday_weather$date, 1, 4)
cta_holiday_weather$month <- substr(cta_holiday_weather$date, 6, 7)
#group by month, take average
cta_holiday_weather_avg_month <- group_by(cta_holiday_weather, month) %>% summarise(total_rides = mean(total_rides))
#Monthly Ridership Graph
ggplot(cta_holiday_weather_avg_month, aes(x = month, y = total_rides, fill = month)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + labs(x = "Month", y = "Average Riders", title = "Average Riders by Month")
#Annual Ridership Graph
cta_holiday_weather_avg_year <- group_by(cta_holiday_weather, year) %>% summarise(total_rides = mean(total_rides))
ggplot(cta_holiday_weather_avg_year, aes(x = year, y = total_rides, fill = year)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + labs(x = "Year", y = "Average Riders", title = "Average Riders by Year")
#group by day_type
cta_holiday_weather_day_type <- group_by(cta_holiday_weather, day_type) %>% summarise(total_rides = mean(total_rides))
#Day Type
ggplot(cta_holiday_weather_day_type, aes(x = day_type, y = total_rides, fill = day_type)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + labs(x = "Day Type", y = "Average Riders", title = "Average Riders per Day Type") + scale_x_discrete(labels = c("Saturday","Sunday/Holiday", "Weekday"))
#group by rain_type
cta_holiday_weather_rain_type <- group_by(cta_holiday_weather, rain_type) %>% summarise(total_rides = mean(total_rides))
#Rain type
ggplot(cta_holiday_weather_rain_type, aes(x = rain_type, y = total_rides, fill = rain_type)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + labs(x = "Rain Type", y = "Average Riders", title = "Average Riders per Rain Type") + scale_x_discrete(labels = c("Clear","Drizzle", "Rain", "Heavy Rain"))
save.image("Wrangling_Project")
save.image("Wrangling_Project.rda")
